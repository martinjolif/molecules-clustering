{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7fafc49",
   "metadata": {},
   "source": [
    "### Importation of the different libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c5a82eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T14:17:19.969279Z",
     "start_time": "2024-01-31T14:17:18.705147Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import Birch, DBSCAN, OPTICS, AgglomerativeClustering, BisectingKMeans, KMeans, MeanShift\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import HDBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import davies_bouldin_score, silhouette_score, calinski_harabasz_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#import tensorflow as tf\n",
    "#import tensorflow.keras as tfk\n",
    "#import tensorflow.keras.layers as tfkl\n",
    "#from keras import regularizers\n",
    "#from keras.models import load_model\n",
    "#from tensorflow.keras.models import Model, load_model\n",
    "#from tensorflow.keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dffbf7",
   "metadata": {},
   "source": [
    "### Load the \"cleaned\" matrix created in the feature_generation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b4e7a86d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T12:52:30.045965Z",
     "start_time": "2024-01-26T12:52:29.033565Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_df = pd.read_csv('cleaned.csv')\n",
    "cleaned = cleaned_df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecf3fc6",
   "metadata": {},
   "source": [
    "### AE train"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[106], line 121\u001B[0m\n\u001B[1;32m    117\u001B[0m         train_losses\u001B[38;5;241m.\u001B[39mappend(train_loss \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(trainloader\u001B[38;5;241m.\u001B[39mdataset))\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, epochs \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m--> 121\u001B[0m     \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m###########################################################################\u001B[39;00m\n\u001B[1;32m    124\u001B[0m z_output \u001B[38;5;241m=\u001B[39m []\n",
      "Cell \u001B[0;32mIn[106], line 110\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(epoch)\u001B[0m\n\u001B[1;32m    108\u001B[0m recon_batch, z \u001B[38;5;241m=\u001B[39m model(data)\n\u001B[1;32m    109\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_mse(recon_batch, data)\n\u001B[0;32m--> 110\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    111\u001B[0m train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m    112\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/Documents/A-Ecole/2A/Projet Recherche/molecules-clustering/venv/lib/python3.11/site-packages/torch/_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    491\u001B[0m     )\n\u001B[0;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/A-Ecole/2A/Projet Recherche/molecules-clustering/venv/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_set = np.float32(cleaned)\n",
    "trainloader = DataLoader(dataset=data_set, batch_size=1024)\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, D_in, H=50, H2=12, latent_dim=32):\n",
    "\n",
    "        # Encoder\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.lin_bn1 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear2 = nn.Linear(H, H2)\n",
    "        self.lin_bn2 = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear3 = nn.Linear(H2, H2)\n",
    "        self.lin_bn3 = nn.BatchNorm1d(num_features=H2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(H2, latent_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=latent_dim)\n",
    "\n",
    "        #         # Decoder\n",
    "        self.fc3 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc_bn3 = nn.BatchNorm1d(latent_dim)\n",
    "        self.fc4 = nn.Linear(latent_dim, H2)\n",
    "        self.fc_bn4 = nn.BatchNorm1d(H2)\n",
    "        \n",
    "        self.linear4 = nn.Linear(H2, H2)\n",
    "        self.lin_bn4 = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear5 = nn.Linear(H2, H)\n",
    "        self.lin_bn5 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear6 = nn.Linear(H, D_in)\n",
    "        self.lin_bn6 = nn.BatchNorm1d(num_features=D_in)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def encode(self, x):\n",
    "        lin1 = self.relu(self.lin_bn1(self.linear1(x)))\n",
    "        lin2 = self.relu(self.lin_bn2(self.linear2(lin1)))\n",
    "        lin3 = self.relu(self.lin_bn3(self.linear3(lin2)))\n",
    "\n",
    "        fc1 = F.relu(self.bn1(self.fc1(lin3)))\n",
    "\n",
    "        return fc1\n",
    "\n",
    "    def decode(self, z):\n",
    "        fc3 = self.relu(self.fc_bn3(self.fc3(z)))\n",
    "        fc4 = self.relu(self.fc_bn4(self.fc4(fc3)))\n",
    "\n",
    "        lin4 = self.relu(self.lin_bn4(self.linear4(fc4)))\n",
    "        lin5 = self.relu(self.lin_bn5(self.linear5(lin4)))\n",
    "        \n",
    "        return self.lin_bn6(self.linear6(lin5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        \n",
    "        return self.decode(z), z\n",
    "\n",
    "\n",
    "###################################################################\n",
    "class customLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(customLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "    def forward(self, x_recon, x):\n",
    "        loss_MSE = self.mse_loss(x_recon, x)\n",
    "\n",
    "        return loss_MSE \n",
    "\n",
    "\n",
    "######################################################################\n",
    "# takes in a module and applies the specified weight initialization\n",
    "def weights_init_uniform_rule(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        # get the number of the inputs\n",
    "        n = m.in_features\n",
    "        y = 1.0 / np.sqrt(n)\n",
    "        m.weight.data.uniform_(-y, y)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "########################################################################\n",
    "D_in = 251\n",
    "H = 50\n",
    "H2 = 12\n",
    "model = Autoencoder(D_in, H, H2).to(device)\n",
    "model.apply(weights_init_uniform_rule)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_mse = customLoss()\n",
    "\n",
    "#########################################################################\n",
    "# Training\n",
    "epochs = 1000\n",
    "log_interval = 50\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(trainloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, z = model(data)\n",
    "        loss = loss_mse(recon_batch, data)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 200 == 0:\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "            epoch, train_loss / len(trainloader.dataset)))\n",
    "        train_losses.append(train_loss / len(trainloader.dataset))\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "\n",
    "###########################################################################\n",
    "z_output = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (data) in enumerate(trainloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, z = model(data)\n",
    "\n",
    "        z_tensor = z\n",
    "        z_output.append(z_tensor)\n",
    "        z_result = torch.cat(z_output, dim=0)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "pred = z_result.cpu().detach().numpy()\n",
    "np.save('pred_ae32_1000_epochs.npy', pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:52:32.401068Z",
     "start_time": "2024-01-26T12:52:30.052477Z"
    }
   },
   "id": "9d580b64f48dbf3a",
   "execution_count": 106
  },
  {
   "cell_type": "markdown",
   "id": "b6f6cc2c",
   "metadata": {},
   "source": [
    "### VAE train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16194e3b",
   "metadata": {},
   "source": [
    "This step takes 9 minutes with Google collab T4 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee89a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T12:52:32.521451Z",
     "start_time": "2024-01-26T12:52:32.401525Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_set = np.float32(cleaned)\n",
    "trainloader = DataLoader(dataset=data_set, batch_size=1024)\n",
    "\n",
    "\n",
    "class VariationnalAutoencoder(nn.Module):\n",
    "    def __init__(self, D_in, H=50, H2=12, latent_dim=32):\n",
    "\n",
    "        # Encoder\n",
    "        super(VariationnalAutoencoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.lin_bn1 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear2 = nn.Linear(H, H2)\n",
    "        self.lin_bn2 = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear3 = nn.Linear(H2, H2)\n",
    "        self.lin_bn3 = nn.BatchNorm1d(num_features=H2)\n",
    "\n",
    "        #         # Latent vectors mu and sigma\n",
    "        self.fc1 = nn.Linear(H2, latent_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=latent_dim)\n",
    "        self.fc21 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc22 = nn.Linear(latent_dim, latent_dim)\n",
    "\n",
    "        #         # Sampling vector\n",
    "        self.fc3 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc_bn3 = nn.BatchNorm1d(latent_dim)\n",
    "        self.fc4 = nn.Linear(latent_dim, H2)\n",
    "        self.fc_bn4 = nn.BatchNorm1d(H2)\n",
    "\n",
    "        #         # Decoder\n",
    "        self.linear4 = nn.Linear(H2, H2)\n",
    "        self.lin_bn4 = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear5 = nn.Linear(H2, H)\n",
    "        self.lin_bn5 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear6 = nn.Linear(H, D_in)\n",
    "        self.lin_bn6 = nn.BatchNorm1d(num_features=D_in)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def encode(self, x):\n",
    "        lin1 = self.relu(self.lin_bn1(self.linear1(x)))\n",
    "        lin2 = self.relu(self.lin_bn2(self.linear2(lin1)))\n",
    "        lin3 = self.relu(self.lin_bn3(self.linear3(lin2)))\n",
    "\n",
    "        fc1 = F.relu(self.bn1(self.fc1(lin3)))\n",
    "\n",
    "        r1 = self.fc21(fc1)\n",
    "        r2 = self.fc22(fc1)\n",
    "\n",
    "        return r1, r2\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "\n",
    "    def decode(self, z):\n",
    "        fc3 = self.relu(self.fc_bn3(self.fc3(z)))\n",
    "        fc4 = self.relu(self.fc_bn4(self.fc4(fc3)))\n",
    "\n",
    "        lin4 = self.relu(self.lin_bn4(self.linear4(fc4)))\n",
    "        lin5 = self.relu(self.lin_bn5(self.linear5(lin4)))\n",
    "        return self.lin_bn6(self.linear6(lin5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "\n",
    "        return self.decode(z), mu, logvar, z\n",
    "\n",
    "\n",
    "###################################################################\n",
    "class customLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(customLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "    def forward(self, x_recon, x, mu, logvar):\n",
    "        loss_MSE = self.mse_loss(x_recon, x)\n",
    "        loss_KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "        return loss_MSE + loss_KLD\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# takes in a module and applies the specified weight initialization\n",
    "def weights_init_uniform_rule(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        # get the number of the inputs\n",
    "        n = m.in_features\n",
    "        y = 1.0 / np.sqrt(n)\n",
    "        m.weight.data.uniform_(-y, y)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "########################################################################\n",
    "D_in = 251\n",
    "H = 50\n",
    "H2 = 12\n",
    "model = VariationnalAutoencoder(D_in, H, H2).to(device)\n",
    "model.apply(weights_init_uniform_rule)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_mse = customLoss()\n",
    "\n",
    "#########################################################################\n",
    "# Training\n",
    "epochs = 1000\n",
    "log_interval = 50\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(trainloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar, z = model(data)\n",
    "        loss = loss_mse(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        #        if batch_idx % log_interval == 0:\n",
    "        #            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        #                epoch, batch_idx * len(data), len(trainloader.dataset),\n",
    "        #                       100. * batch_idx / len(trainloader),\n",
    "        #                       loss.item() / len(data)))\n",
    "    if epoch % 200 == 0:\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "            epoch, train_loss / len(trainloader.dataset)))\n",
    "        train_losses.append(train_loss / len(trainloader.dataset))\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "\n",
    "###########################################################################\n",
    "mu_output = []\n",
    "logvar_output = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (data) in enumerate(trainloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar, z = model(data)\n",
    "\n",
    "        mu_tensor = mu\n",
    "        mu_output.append(mu_tensor)\n",
    "        mu_result = torch.cat(mu_output, dim=0)\n",
    "\n",
    "        logvar_tensor = logvar\n",
    "        logvar_output.append(logvar_tensor)\n",
    "        logvar_result = torch.cat(logvar_output, dim=0)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "pred = mu_result.cpu().detach().numpy()\n",
    "np.save('pred_vae32_1500_epochs.npy', pred)\n",
    "\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b49ec",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.402587Z"
    }
   },
   "outputs": [],
   "source": [
    "VAE_32 = np.load('pred_vae32_1500_epochs.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68182a0f",
   "metadata": {},
   "source": [
    "### Choose the best number of clusters (K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08fee60",
   "metadata": {},
   "source": [
    "This step take a lot of time because of the computation time of the silhouette coefficient (45min with google collab CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b443110a",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.403531Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_array = VAE_32\n",
    "km_scores = []\n",
    "vae32 = []\n",
    "db_score = []\n",
    "for i in range(5, 200, 5):\n",
    "    km = KMeans(n_clusters=i, random_state=25, n_init=10).fit(loaded_array)\n",
    "    km_preds = km.predict(loaded_array)\n",
    "    \n",
    "    #Calculating the silhouette coefficiant takes time\n",
    "    silhouette = silhouette_score(loaded_array, km_preds, random_state=25)\n",
    "    vae32.append(silhouette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b1b56",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.404556Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(250, 80))\n",
    "plt.title(\"\", fontsize=96)\n",
    "plt.scatter(x=[i for i in range(5, 200, 5)], y=vae32, s=6000, edgecolor='k', color='blue')\n",
    "plt.grid(True, linewidth=10)\n",
    "plt.xlabel(\"\\nNumber of clusters for the K-means Model\", fontsize=180)\n",
    "plt.ylabel(\"Silhouette score\\n\", fontsize=180)\n",
    "plt.xticks([i for i in range(5, 200, 5)], fontsize=150)\n",
    "plt.yticks(fontsize=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e2e553",
   "metadata": {},
   "source": [
    "### BIRCH train & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad0aa7e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.405396Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_array = cleaned\n",
    "\n",
    "brc = Birch(threshold=0.5, branching_factor=50, n_clusters=30, compute_labels=True, copy=True)\n",
    "brc.fit(loaded_array)\n",
    "birch_labels = brc.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574d7605",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.406290Z"
    }
   },
   "outputs": [],
   "source": [
    "ch = metrics.calinski_harabasz_score(loaded_array, birch_labels)\n",
    "print('ch Score: %.3f' % ch)\n",
    "\n",
    "ss = silhouette_score(loaded_array, birch_labels, metric='euclidean')\n",
    "print('Silhouetter Score: %.3f' % ss)\n",
    "\n",
    "DB = davies_bouldin_score(loaded_array, birch_labels)\n",
    "print('DB Score: %.3f' % DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d075be30",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.407213Z"
    }
   },
   "outputs": [],
   "source": [
    "VAE_16 = np.load('pred_vae16_1000_epochs.npy')\n",
    "VAE_32 = np.load('pred_vae32_1000_epochs.npy')\n",
    "VAE_64 = np.load('pred_vae64_1000_epochs.npy')\n",
    "AE_32 = np.load('pred_ae32_1000_epochs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(VAE_32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.408028Z"
    }
   },
   "id": "9215ed91d86625ca",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c0c89fd9",
   "metadata": {},
   "source": [
    "### Kmeans Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc86b1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.408917Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_array = VAE_32\n",
    "\n",
    "##K-Means & Internal clustering evaluations\n",
    "kmeans = KMeans(50,random_state=21, n_init=20)\n",
    "kmeans.fit(loaded_array)\n",
    "kmeanslabels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032dbe7c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.409699Z"
    }
   },
   "outputs": [],
   "source": [
    "ch = metrics.calinski_harabasz_score(loaded_array, kmeanslabels)\n",
    "print('ch Score: %.3f' % ch)\n",
    "\n",
    "ss = silhouette_score(loaded_array, kmeanslabels, metric='euclidean')\n",
    "print('Silhouetter Score: %.3f' % ss)\n",
    "\n",
    "DB = davies_bouldin_score(loaded_array, kmeanslabels)\n",
    "print('DB Score: %.3f' % DB)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "kmeanslabels_df = pd.DataFrame(kmeanslabels)\n",
    "kmeanslabels_df.to_csv('labels_VAE_32_Kmeans_K50.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.410526Z"
    }
   },
   "id": "d0fa4d0e88da5b1c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3ff93502",
   "metadata": {},
   "source": [
    "### Bisecting Kmeans train & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0bb34",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.411371Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_array = VAE_32\n",
    "\n",
    "for i in range(5,100,5):\n",
    "    print(i)\n",
    "    bisectingkmeans = BisectingKMeans(i,random_state=21, n_init=10)\n",
    "    bisectingkmeans.fit(loaded_array)\n",
    "    labels_bisectingkmeans = bisectingkmeans.labels_\n",
    "\n",
    "    ch = metrics.calinski_harabasz_score(loaded_array, labels_bisectingkmeans)\n",
    "    print('ch Score: %.3f' % ch)\n",
    "\n",
    "    ss = silhouette_score(loaded_array, labels_bisectingkmeans, metric='euclidean')\n",
    "    print('Silhouetter Score: %.3f' % ss)\n",
    "\n",
    "    DB = davies_bouldin_score(loaded_array, labels_bisectingkmeans)\n",
    "    print('DB Score: %.3f' % DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a1a8a",
   "metadata": {},
   "source": [
    "### DBSCAN train & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5deeb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.412248Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_array = VAE_32\n",
    "\n",
    "EPS = 2\n",
    "\n",
    "Dbscan = DBSCAN(eps = EPS)\n",
    "Dbscan.fit(loaded_array)\n",
    "labels_DBSCAN = Dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9158be7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.413030Z"
    }
   },
   "outputs": [],
   "source": [
    "# taking an input list\n",
    "input_list = labels_DBSCAN\n",
    "\n",
    "l1 = []\n",
    "\n",
    "# taking a counter\n",
    "count = 0\n",
    "\n",
    "for item in input_list:\n",
    "    if item not in l1:\n",
    "        count += 1\n",
    "        l1.append(item)\n",
    "\n",
    "# printing the output\n",
    "print(\"No of unique items are:\", count)\n",
    "print(\"values:\", l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a45cd4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.413879Z"
    }
   },
   "outputs": [],
   "source": [
    "ch = metrics.calinski_harabasz_score(loaded_array, labels_DBSCAN)\n",
    "print('ch Score: %.3f' % ch)\n",
    "\n",
    "ss = silhouette_score(loaded_array, labels_DBSCAN, metric='euclidean')\n",
    "print('Silhouetter Score: %.3f' % ss)\n",
    "\n",
    "DB = davies_bouldin_score(loaded_array, labels_DBSCAN)\n",
    "print('DB Score: %.3f' % DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### HDBSCAN train & evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3a01399e16a963d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loaded_array = VAE_32\n",
    "\n",
    "HDbscan = HDBSCAN(min_cluster_size=100)\n",
    "HDbscan.fit(loaded_array)\n",
    "labels_HDBSCAN = HDbscan.labels_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.414774Z"
    }
   },
   "id": "6862067d94da6701",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# taking an input list\n",
    "input_list = labels_HDBSCAN\n",
    "\n",
    "l1 = []\n",
    "\n",
    "# taking a counter\n",
    "count = 0\n",
    "\n",
    "for item in input_list:\n",
    "    if item not in l1:\n",
    "        count += 1\n",
    "        l1.append(item)\n",
    "\n",
    "# printing the output\n",
    "print(\"No of unique items are:\", count)\n",
    "print(\"values:\", l1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.415610Z"
    }
   },
   "id": "8bedc1ee10b93c18",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ch = metrics.calinski_harabasz_score(loaded_array, labels_HDBSCAN)\n",
    "print('ch Score: %.3f' % ch)\n",
    "\n",
    "ss = silhouette_score(loaded_array, labels_HDBSCAN, metric='euclidean')\n",
    "print('Silhouetter Score: %.3f' % ss)\n",
    "\n",
    "DB = davies_bouldin_score(loaded_array, labels_HDBSCAN)\n",
    "print('DB Score: %.3f' % DB)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.416388Z"
    }
   },
   "id": "c3b2aa934067bcc2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c93ae7de",
   "metadata": {},
   "source": [
    "### OPTICS train & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac38224",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.417132Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_array = VAE_32\n",
    "\n",
    "Optics = OPTICS(min_samples = 50)\n",
    "Optics.fit(loaded_array)\n",
    "labels_OPTICS = Optics.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8192fef",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.417883Z"
    }
   },
   "outputs": [],
   "source": [
    "# taking an input list\n",
    "input_list = labels_OPTICS\n",
    "\n",
    "l1 = []\n",
    "\n",
    "# taking a counter\n",
    "count = 0\n",
    "\n",
    "for item in input_list:\n",
    "    if item not in l1:\n",
    "        count += 1\n",
    "        l1.append(item)\n",
    "\n",
    "# printing the output\n",
    "print(\"No of unique items are:\", count)\n",
    "print(\"values:\", l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bced813",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.418713Z"
    }
   },
   "outputs": [],
   "source": [
    "ch = metrics.calinski_harabasz_score(loaded_array, labels_OPTICS)\n",
    "print('ch Score: %.3f' % ch)\n",
    "\n",
    "ss = silhouette_score(loaded_array, labels_OPTICS, metric='euclidean')\n",
    "print('Silhouetter Score: %.3f' % ss)\n",
    "\n",
    "DB = davies_bouldin_score(loaded_array, labels_OPTICS)\n",
    "print('DB Score: %.3f' % DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49653922",
   "metadata": {},
   "source": [
    "### Meanshift train & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369d9b2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.419210Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_array = VAE_32\n",
    "\n",
    "\n",
    "meanshift = MeanShift(bandwidth = 3)\n",
    "meanshift.fit(loaded_array)\n",
    "labels_meanshift = meanshift.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02af913b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.419742Z"
    }
   },
   "outputs": [],
   "source": [
    "# taking an input list\n",
    "input_list = labels_meanshift\n",
    "\n",
    "l1 = []\n",
    "\n",
    "# taking a counter\n",
    "count = 0\n",
    "\n",
    "for item in input_list:\n",
    "    if item not in l1:\n",
    "        count += 1\n",
    "        l1.append(item)\n",
    "\n",
    "# printing the output\n",
    "print(\"No of unique items are:\", count)\n",
    "print(\"values:\", l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43b53c5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.420269Z"
    }
   },
   "outputs": [],
   "source": [
    "ch = metrics.calinski_harabasz_score(loaded_array, labels_meanshift)\n",
    "print('ch Score: %.3f' % ch)\n",
    "\n",
    "ss = silhouette_score(loaded_array, labels_meanshift, metric='euclidean')\n",
    "print('Silhouetter Score: %.3f' % ss)\n",
    "\n",
    "DB = davies_bouldin_score(loaded_array, labels_meanshift)\n",
    "print('DB Score: %.3f' % DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fb0245",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.420811Z"
    }
   },
   "outputs": [],
   "source": [
    "meanshift.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf5b723",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e016b8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.421327Z"
    }
   },
   "outputs": [],
   "source": [
    "## Visualize Results\n",
    "labels_df = pd.read_csv('labels_VAE_32_Kmeans_K50.csv')\n",
    "labels = labels_df.to_numpy()\n",
    "\n",
    "# 1. Density Plot\n",
    "pred = pd.DataFrame(data=VAE_32)\n",
    "\n",
    "\n",
    "molecules = pd.read_csv(\"compound-annotation.csv\", sep=\",\")\n",
    "molecules = molecules[molecules[\"SMILES\"].notna()]\n",
    "molecules = molecules.drop_duplicates(subset=['SMILES'], ignore_index=True)\n",
    "smiles = molecules[[\"SMILES\"]]\n",
    "\n",
    "pred.insert(0, 'SMILES', smiles)\n",
    "\n",
    "pred.insert(1, \"clusters\", labels)\n",
    "\n",
    "s = []\n",
    "i = 0\n",
    "index = []\n",
    "K = 50 #number of clusters\n",
    "for j in range(0, K):\n",
    "    s = pred.loc[pred['clusters'] == j, 'SMILES']\n",
    "    s = s.to_list()\n",
    "    for s2 in s:\n",
    "        i = i + 1\n",
    "    index.append(i)\n",
    "    i = 0\n",
    "\n",
    "###################################\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "x = []\n",
    "for i in range(1, K+1):\n",
    "    x.append(i)\n",
    "\n",
    "font = {'size': 22}\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "langs = x\n",
    "students = index\n",
    "ax.bar(langs, students)\n",
    "ax.set_ylabel('Number of molecules in each cluster\\n', fontsize=34)\n",
    "ax.set_xlabel('\\nNumber of clusters ', fontsize=34)\n",
    "ax.set_xticks([k for k in range(0, K+1, 10)])\n",
    "#ax.set_xticks( fontsize = 20)\n",
    "ax.set_title('', fontsize=14)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224f360a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.421870Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. t-SNE plot\n",
    "loaded_array = VAE_pred\n",
    "labels = labels_VAE_Kmeans\n",
    "\n",
    "tsne_comp = TSNE(n_components=2, perplexity=30, random_state=30, n_iter=1000).fit_transform(loaded_array)\n",
    "\n",
    "tsne_df = pd.DataFrame(data=tsne_comp, columns=['t-SNE1', 't-SNE2'])\n",
    "tsne_df.head()\n",
    "\n",
    "tsne_df = pd.concat([tsne_df, pd.DataFrame({'cluster': labels})], axis=1)\n",
    "tsne_df['cluster'] += 1\n",
    "tsne_df.head()\n",
    "\n",
    "text = []\n",
    "for i in range(1, 31):\n",
    "    text.append(str(i))\n",
    "len(text)\n",
    "\n",
    "plt.figure(figsize=(25, 20))\n",
    "sns.set(font_scale=3)\n",
    "z = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "ax = sns.scatterplot(x=\"t-SNE1\", y=\"t-SNE2\", hue=\"cluster\", data=tsne_df, palette=z)\n",
    "# ax = sns.color_palette(\"mako\", as_cmap=True)\n",
    "x = tsne_df['t-SNE1']\n",
    "y = tsne_df['t-SNE2']\n",
    "for i in range(0, 30):\n",
    "    plt.annotate(text[i], (x[i], y[i] + .2), size=22, color='black', weight='bold')\n",
    "# plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0, ncol = 3 )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0b0da5",
   "metadata": {},
   "source": [
    "### Resume of the results obtained for each methods used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09da1a2",
   "metadata": {},
   "source": [
    "Be careful the score for the method using the VAE are computed in the latent space and not in the 'entire' departures space. So, we can not compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1103399",
   "metadata": {},
   "source": [
    "###### Kmeans in the entire Space"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The metrics have been computed in the input space"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e154eaf4cacd6b1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "| dimension of the space of features used in the model | Method of clustering | Number of clusters | eps | thresold | branching factor | CH       | SC    | DB    |\n",
    "|------------------------------------------------------|----------------------|--------------------|-----|----------|------------------|----------|-------|-------|\n",
    "| 251: 'basic' space                                   | Kmeans               | 130                | -   | -        | -                | 533.264  | 0.076 | 1.949 |\n",
    "| 251: 'basic' space                                   | Kmeans               | 30                 | -   | -        | -                | 1011.817 | 0.058 | 2.329 |"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23ff839f505d09c6"
  },
  {
   "cell_type": "markdown",
   "id": "732fb5aa",
   "metadata": {},
   "source": [
    "###### Kmeans in the latent Space"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The metrics have been computed in the latent space\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c64ef04eb4b17bfa"
  },
  {
   "cell_type": "markdown",
   "id": "0fbeb070",
   "metadata": {},
   "source": [
    "| dimension of the space of features used in the model | Method of clustering | Number of clusters | CH           | SC        | DB        |\n",
    "|------------------------------------------------------|----------------------|--------------------|--------------|-----------|-----------|\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 25                 | **6747.221** | 0.239     | 1.100     |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 26                 | 6688.481     | 0.236     | 1.103     |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 27                 | 6616.331     | 0.236     | 1.125     |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 28                 | 6579.824     | 0.239     | 1.105     |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 29                 | 6503.428     | 0.239     | **1.085** |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 30                 | 6452.638     | **0.240** | 1.091     |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 31                 | 6353.183     | 0.234     | 1.130     |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 35                 | 6100.477     | 0.231     | 1.139     |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 40                 | 5901.286     | 0.231     | 1.169     |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 50                 | 5454.641     | 0.232     | 1.153     |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 80                 | 4620.676     | 0.234     | 1.147     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abea9d7",
   "metadata": {},
   "source": [
    "###### BIRCH in the latent Space"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The metrics have been computed in the latent space\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64fbf46ea4752da9"
  },
  {
   "cell_type": "markdown",
   "id": "d3b70b01",
   "metadata": {},
   "source": [
    "| dimension of the space of features used in the model | Method of clustering | Number of clusters | eps | thresold | branching factor | CH           | SC        | DB        |\n",
    "|------------------------------------------------------|----------------------|--------------------|-----|----------|------------------|--------------|-----------|-----------|\n",
    "| 32: 'latent' space (VAE_32)                          | Birch                | 10                 | -   | 0.5      | 50               | 3966.486     | 0.133     | 1.386     |\n",
    "| 32: 'latent' space (VAE_32)                          | Birch                | 15                 | -   | 0.5      | 50               | **4262.498** | 0.129     | 1.334     |\n",
    "| 32: 'latent' space (VAE_32)                          | Birch                | 20                 | -   | 0.5      | 50               | 3832.337     | 0.145     | **1.248** |\n",
    "| 32: 'latent' space (VAE_32)                          | Birch                | 25                 | -   | 0.5      | 50               | 3809.872     | **0.165** | 1.140     |\n",
    "| 32: 'latent' space (VAE_32)                          | Birch                | 30                 | -   | 0.5      | 50               | 3451.681     | 0.151     | 1.140     |\n",
    "| 32: 'latent' space (VAE_32)                          | Birch                | 35                 | -   | 0.5      | 50               | 3589.347     | 0.149     | 1.159     |\n",
    "| 32: 'latent' space (VAE_32)                          | Birch                | 40                 | -   | 0.5      | 50               | 3260.281     | 0.147     | 1.146     |\n",
    "| 32: 'latent' space (VAE_32)                          | Birch                | 45                 | -   | 0.5      | 50               | 3232.431     | 0.154     | 1.168     |\n",
    "| 32: 'latent' space (VAE_32)                          | Birch                | 50                 | -   | 0.5      | 50               | 3080.691     | 0.149     | 1.177     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d707b1",
   "metadata": {},
   "source": [
    "###### DBSCAN in the latent Space"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The metrics have been computed in the latent space"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb12862c60dec64d"
  },
  {
   "cell_type": "markdown",
   "id": "38d76c61",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| dimension of the space of features used in the model | Method of clustering | Number of clusters  | eps | CH      | SC     | DB    |\n",
    "|------------------------------------------------------|----------------------|---------------------|-----|---------|--------|-------|\n",
    "| 32: 'latent' space (VAE)                             | DBSCAN               | 94 + outlier points | 0.3 | 170.611 | -0.344 | 1.602 |\n",
    "| 32: 'latent' space (VAE)                             | DBSCAN               | 19 + outlier points | 0.5 | 100.915 | -0.115 | 1.802 |\n",
    "| 32: 'latent' space (VAE)                             | DBSCAN               | 15 + outlier points | 0.6 | 112.517 | 0.094  | 1.631 |\n",
    "| 32: 'latent' space (VAE)                             | DBSCAN               | 12 + outlier points | 0.7 | 137.627 | 0.232  | 1.556 |\n",
    "| 32: 'latent' space (VAE)                             | DBSCAN               | 6 + outlier points  | 0.8 | 198.313 | 0.348  | 1.603 |\n",
    "| 32: 'latent' space (VAE)                             | DBSCAN               | 9 + outlier points  | 1.2 | 148.970 | 0.443  | 1.608 |\n",
    "| 32: 'latent' space (VAE)                             | DBSCAN               | 4 + outlier points  | 1.5 | 128.754 | 0.486  | 1.241 |\n",
    "| 32: 'latent' space (VAE)                             | DBSCAN               | 2 + outlier points  | 2   | 132.724 | 0.575  | 0.968 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9662b30",
   "metadata": {},
   "source": [
    "###### OPTICS in the latent Space"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The metrics have been computed in the latent space\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eeaf06f17c5096d2"
  },
  {
   "cell_type": "markdown",
   "id": "e019bb1b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| dimension of the space of features used in the model | Method of clustering | Number of clusters    | min_samples | max_eps                | CH      | SC     | DB    |\n",
    "|------------------------------------------------------|----------------------|-----------------------|-------------|------------------------|---------|--------|-------|\n",
    "| 32: 'latent' space (VAE)                             | OPTICS               | 1493 + outlier points | 5           | np.inf (default value) | 11.185  | -0.532 | 1.236 |\n",
    "| 32: 'latent' space (VAE)                             | OPTICS               | 280 + outlier points  | 10          | np.inf (default value) | 25.169  | -0.636 | 1.116 |\n",
    "| 32: 'latent' space (VAE)                             | OPTICS               | 107 + outlier points  | 15          | np.inf (default value) | 47.644  | -0.598 | 1.012 |\n",
    "| 32: 'latent' space (VAE)                             | OPTICS               | 23 + outlier points   | 25          | np.inf (default value) | 113.761 | -0.355 | 0.928 |\n",
    "| 32: 'latent' space (VAE)                             | OPTICS               | 5 + outlier points    | 50          | np.inf (default value) | 121.111 | -0.150 | 0.936 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57735e1c",
   "metadata": {},
   "source": [
    "###### Bisecting Kmeans in the latent Space"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The metrics have been computed in the latent space\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9bc7ada0afcde77"
  },
  {
   "cell_type": "markdown",
   "id": "225f64de",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| dimension of the space of features used in the model | Method of clustering | Number of clusters | CH       | SC        | DB    |\n",
    "|------------------------------------------------------|----------------------|--------------------|----------|-----------|-------|\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 5                  | 8112.950 | 0.161     | 1.621 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 10                 | 6677.805 | 0.140     | 1.561 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 15                 | 6371.956 | **0.163** | 1.469 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 20                 | 5715.197 | 0.156     | 1.424 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 25                 | 5190.460 | 0.144     | 1.437 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 30                 | 4971.206 | 0.153     | 1.390 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 35                 | 4753.198 | 0.152     | 1.455 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 40                 | 4671.040 | 0.157     | 1.410 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 45                 | 4443.872 | 0.154     | 1.419 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 50                 | 4242.036 | 0.153     | 1.431 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 60                 | 3952.478 | 0.150     | 1.408 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 70                 | 3695.272 | 0.146     | 1.410 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 80                 | 3516.554 | 0.144     | 1.399 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9e683b",
   "metadata": {},
   "source": [
    "###### Bisecting Kmeans in the latent Space"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The metrics have been computed in the latent space"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb97a847a1fcd9b2"
  },
  {
   "cell_type": "markdown",
   "id": "daa5a0a8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| dimension of the space of features used in the model | Method of clustering | Number of clusters | bandwith | CH      | SC    | DB    |\n",
    "|------------------------------------------------------|----------------------|--------------------|----------|---------|-------|-------|\n",
    "| 32: 'latent' space (VAE)                             | Meanshift            | 22                 | None     | 151.947 | 0.233 | 0.847 |\n",
    "| 32: 'latent' space (VAE)                             | Meanshift            | 8                  | 3        | 213.409 | 0.484 | 1.329 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc82e0e",
   "metadata": {},
   "source": [
    "### Comparaison to the original article"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The metrics have been computed in the input space"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "555cce672aca9dd2"
  },
  {
   "cell_type": "markdown",
   "id": "8ee777b0",
   "metadata": {},
   "source": [
    "| dimension of the space of features used in the model | Clustering method | Number of clusters | CH           | SC        | DB        |\n",
    "|------------------------------------------------------|-------------------|--------------------|--------------|-----------|-----------|\n",
    "| 251: 'input' space                                   | Kmeans            | 30                 | 1011.817     | 0.058     | 2.329     |\n",
    "| 251: 'input' space                                   | BIRCH             | 30                 | 840.342      | 0.042     | 2.181     |\n",
    "| 251: 'input' space                                   | VAE(16) + Kmeans  | 50                 | 4070.465     | 0.204     | 1.253     |\n",
    "| 251: 'input' space                                   | VAE(32) + Kmeans  | 50                 | **5472.521** | **0.230** | **1.172** | \n",
    "| 251: 'input' space                                   | VAE(64) + Kmeans  | 70                 | 2116.804     | 0.156     | 1.425     |\n",
    "| 251: 'input' space                                   | Kmeans            | 50                 | 805.715      | 0.064     | 2.060     |"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "| dimension of the space of features used in the model | Method of clustering        | Number of clusters  | CH           | SC        | DB        |\n",
    "|------------------------------------------------------|-----------------------------|---------------------|--------------|-----------|-----------|\n",
    "| 32: 'latent' space (VAE)                             | VAE (32) + DBSCAN           | 19 + outlier points | 100.915      | -0.115    | 1.802     |\n",
    "| 32: 'latent' space (VAE)                             | VAE (32) + DBSCAN           | 12 + outlier points | 137.627      | 0.232     | 1.556     |\n",
    "| 32: 'latent' space (VAE)                             | VAE (32) + Meanshift        | 22                  | 151.947      | 0.233     | **0.847** |\n",
    "| 32: 'latent' space (VAE)                             | VAE (32) + Meanshift        | 8                   | 213.409      | **0.484** | 1.329     |\n",
    "| 32: 'latent' space (VAE)                             | VAE (32) + HDBSCAN          | 11 + outlier points | 652.650      | -0.123    | 2.234     |\n",
    "| 32: 'latent' space (VAE)                             | VAE (32) + Birch            | 15                  | 4262.498     | 0.129     | 1.334     |\n",
    "| 32: 'latent' space (VAE)                             | VAE (32) + Kmeans           | 15                  | **7575.908** | 0.223     | 1.199     |\n",
    "| 32: 'latent' space (VAE)                             | VAE (32) + Bisecting Kmeans | 15                  | 6371.956     | 0.163     | 1.469     |"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bb81b00a5e057b3"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4b69491ad66f1dd5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "| Method of clustering | Number of clusters  | CH           | SC        | DB        |\n",
    "|----------------------|---------------------|--------------|-----------|-----------|\n",
    "| DBSCAN               | 19 + outlier points | 100.915      | -0.115    | 1.802     |\n",
    "| DBSCAN               | 12 + outlier points | 137.627      | 0.232     | 1.556     |\n",
    "| Meanshift            | 22                  | 151.947      | 0.233     | **0.847** |\n",
    "| Meanshift            | 8                   | 213.409      | **0.484** | 1.329     |\n",
    "| HDBSCAN              | 11 + outlier points | 652.650      | -0.123    | 2.234     |\n",
    "| Birch                | 15                  | 4262.498     | 0.129     | 1.334     |\n",
    "| Kmeans               | 15                  | **7575.908** | 0.223     | 1.199     |\n",
    "| Bisecting Kmeans     | 15                  | 6371.956     | 0.163     | 1.469     |"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a41a7324caec11f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
