{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7fafc49",
   "metadata": {},
   "source": [
    "### Importation of the different libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5c5a82eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T12:52:29.032404Z",
     "start_time": "2024-01-26T12:52:28.930313Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import Birch, DBSCAN, OPTICS, AgglomerativeClustering, BisectingKMeans, KMeans, MeanShift\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import HDBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import davies_bouldin_score, silhouette_score, calinski_harabasz_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#import tensorflow as tf\n",
    "#import tensorflow.keras as tfk\n",
    "#import tensorflow.keras.layers as tfkl\n",
    "#from keras import regularizers\n",
    "#from keras.models import load_model\n",
    "#from tensorflow.keras.models import Model, load_model\n",
    "#from tensorflow.keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dffbf7",
   "metadata": {},
   "source": [
    "### Load the \"cleaned\" matrix created in the feature_generation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b4e7a86d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T12:52:30.045965Z",
     "start_time": "2024-01-26T12:52:29.033565Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_df = pd.read_csv('cleaned.csv')\n",
    "cleaned = cleaned_df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecf3fc6",
   "metadata": {},
   "source": [
    "### AE train"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[106], line 121\u001B[0m\n\u001B[1;32m    117\u001B[0m         train_losses\u001B[38;5;241m.\u001B[39mappend(train_loss \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(trainloader\u001B[38;5;241m.\u001B[39mdataset))\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, epochs \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m--> 121\u001B[0m     \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m###########################################################################\u001B[39;00m\n\u001B[1;32m    124\u001B[0m z_output \u001B[38;5;241m=\u001B[39m []\n",
      "Cell \u001B[0;32mIn[106], line 110\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(epoch)\u001B[0m\n\u001B[1;32m    108\u001B[0m recon_batch, z \u001B[38;5;241m=\u001B[39m model(data)\n\u001B[1;32m    109\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_mse(recon_batch, data)\n\u001B[0;32m--> 110\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    111\u001B[0m train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m    112\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/Documents/A-Ecole/2A/Projet Recherche/molecules-clustering/venv/lib/python3.11/site-packages/torch/_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    491\u001B[0m     )\n\u001B[0;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/A-Ecole/2A/Projet Recherche/molecules-clustering/venv/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_set = np.float32(cleaned)\n",
    "trainloader = DataLoader(dataset=data_set, batch_size=1024)\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, D_in, H=50, H2=12, latent_dim=32):\n",
    "\n",
    "        # Encoder\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.lin_bn1 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear2 = nn.Linear(H, H2)\n",
    "        self.lin_bn2 = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear3 = nn.Linear(H2, H2)\n",
    "        self.lin_bn3 = nn.BatchNorm1d(num_features=H2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(H2, latent_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=latent_dim)\n",
    "\n",
    "        #         # Decoder\n",
    "        self.fc3 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc_bn3 = nn.BatchNorm1d(latent_dim)\n",
    "        self.fc4 = nn.Linear(latent_dim, H2)\n",
    "        self.fc_bn4 = nn.BatchNorm1d(H2)\n",
    "        \n",
    "        self.linear4 = nn.Linear(H2, H2)\n",
    "        self.lin_bn4 = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear5 = nn.Linear(H2, H)\n",
    "        self.lin_bn5 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear6 = nn.Linear(H, D_in)\n",
    "        self.lin_bn6 = nn.BatchNorm1d(num_features=D_in)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def encode(self, x):\n",
    "        lin1 = self.relu(self.lin_bn1(self.linear1(x)))\n",
    "        lin2 = self.relu(self.lin_bn2(self.linear2(lin1)))\n",
    "        lin3 = self.relu(self.lin_bn3(self.linear3(lin2)))\n",
    "\n",
    "        fc1 = F.relu(self.bn1(self.fc1(lin3)))\n",
    "\n",
    "        return fc1\n",
    "\n",
    "    def decode(self, z):\n",
    "        fc3 = self.relu(self.fc_bn3(self.fc3(z)))\n",
    "        fc4 = self.relu(self.fc_bn4(self.fc4(fc3)))\n",
    "\n",
    "        lin4 = self.relu(self.lin_bn4(self.linear4(fc4)))\n",
    "        lin5 = self.relu(self.lin_bn5(self.linear5(lin4)))\n",
    "        \n",
    "        return self.lin_bn6(self.linear6(lin5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        \n",
    "        return self.decode(z), z\n",
    "\n",
    "\n",
    "###################################################################\n",
    "class customLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(customLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "    def forward(self, x_recon, x):\n",
    "        loss_MSE = self.mse_loss(x_recon, x)\n",
    "\n",
    "        return loss_MSE \n",
    "\n",
    "\n",
    "######################################################################\n",
    "# takes in a module and applies the specified weight initialization\n",
    "def weights_init_uniform_rule(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        # get the number of the inputs\n",
    "        n = m.in_features\n",
    "        y = 1.0 / np.sqrt(n)\n",
    "        m.weight.data.uniform_(-y, y)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "########################################################################\n",
    "D_in = 251\n",
    "H = 50\n",
    "H2 = 12\n",
    "model = Autoencoder(D_in, H, H2).to(device)\n",
    "model.apply(weights_init_uniform_rule)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_mse = customLoss()\n",
    "\n",
    "#########################################################################\n",
    "# Training\n",
    "epochs = 1000\n",
    "log_interval = 50\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(trainloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, z = model(data)\n",
    "        loss = loss_mse(recon_batch, data)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 200 == 0:\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "            epoch, train_loss / len(trainloader.dataset)))\n",
    "        train_losses.append(train_loss / len(trainloader.dataset))\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "\n",
    "###########################################################################\n",
    "z_output = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (data) in enumerate(trainloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, z = model(data)\n",
    "\n",
    "        z_tensor = z\n",
    "        z_output.append(z_tensor)\n",
    "        z_result = torch.cat(z_output, dim=0)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "pred = z_result.cpu().detach().numpy()\n",
    "np.save('pred_ae32_1000_epochs.npy', pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:52:32.401068Z",
     "start_time": "2024-01-26T12:52:30.052477Z"
    }
   },
   "id": "9d580b64f48dbf3a",
   "execution_count": 106
  },
  {
   "cell_type": "markdown",
   "id": "b6f6cc2c",
   "metadata": {},
   "source": [
    "### VAE train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16194e3b",
   "metadata": {},
   "source": [
    "This step takes 9 minutes with Google collab T4 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee89a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T12:52:32.521451Z",
     "start_time": "2024-01-26T12:52:32.401525Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_set = np.float32(cleaned)\n",
    "trainloader = DataLoader(dataset=data_set, batch_size=1024)\n",
    "\n",
    "\n",
    "class VariationnalAutoencoder(nn.Module):\n",
    "    def __init__(self, D_in, H=50, H2=12, latent_dim=32):\n",
    "\n",
    "        # Encoder\n",
    "        super(VariationnalAutoencoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.lin_bn1 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear2 = nn.Linear(H, H2)\n",
    "        self.lin_bn2 = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear3 = nn.Linear(H2, H2)\n",
    "        self.lin_bn3 = nn.BatchNorm1d(num_features=H2)\n",
    "\n",
    "        #         # Latent vectors mu and sigma\n",
    "        self.fc1 = nn.Linear(H2, latent_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=latent_dim)\n",
    "        self.fc21 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc22 = nn.Linear(latent_dim, latent_dim)\n",
    "\n",
    "        #         # Sampling vector\n",
    "        self.fc3 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc_bn3 = nn.BatchNorm1d(latent_dim)\n",
    "        self.fc4 = nn.Linear(latent_dim, H2)\n",
    "        self.fc_bn4 = nn.BatchNorm1d(H2)\n",
    "\n",
    "        #         # Decoder\n",
    "        self.linear4 = nn.Linear(H2, H2)\n",
    "        self.lin_bn4 = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear5 = nn.Linear(H2, H)\n",
    "        self.lin_bn5 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear6 = nn.Linear(H, D_in)\n",
    "        self.lin_bn6 = nn.BatchNorm1d(num_features=D_in)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def encode(self, x):\n",
    "        lin1 = self.relu(self.lin_bn1(self.linear1(x)))\n",
    "        lin2 = self.relu(self.lin_bn2(self.linear2(lin1)))\n",
    "        lin3 = self.relu(self.lin_bn3(self.linear3(lin2)))\n",
    "\n",
    "        fc1 = F.relu(self.bn1(self.fc1(lin3)))\n",
    "\n",
    "        r1 = self.fc21(fc1)\n",
    "        r2 = self.fc22(fc1)\n",
    "\n",
    "        return r1, r2\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "\n",
    "    def decode(self, z):\n",
    "        fc3 = self.relu(self.fc_bn3(self.fc3(z)))\n",
    "        fc4 = self.relu(self.fc_bn4(self.fc4(fc3)))\n",
    "\n",
    "        lin4 = self.relu(self.lin_bn4(self.linear4(fc4)))\n",
    "        lin5 = self.relu(self.lin_bn5(self.linear5(lin4)))\n",
    "        return self.lin_bn6(self.linear6(lin5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "\n",
    "        return self.decode(z), mu, logvar, z\n",
    "\n",
    "\n",
    "###################################################################\n",
    "class customLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(customLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "    def forward(self, x_recon, x, mu, logvar):\n",
    "        loss_MSE = self.mse_loss(x_recon, x)\n",
    "        loss_KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "        return loss_MSE + loss_KLD\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# takes in a module and applies the specified weight initialization\n",
    "def weights_init_uniform_rule(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        # get the number of the inputs\n",
    "        n = m.in_features\n",
    "        y = 1.0 / np.sqrt(n)\n",
    "        m.weight.data.uniform_(-y, y)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "########################################################################\n",
    "D_in = 251\n",
    "H = 50\n",
    "H2 = 12\n",
    "model = VariationnalAutoencoder(D_in, H, H2).to(device)\n",
    "model.apply(weights_init_uniform_rule)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_mse = customLoss()\n",
    "\n",
    "#########################################################################\n",
    "# Training\n",
    "epochs = 1000\n",
    "log_interval = 50\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(trainloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar, z = model(data)\n",
    "        loss = loss_mse(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        #        if batch_idx % log_interval == 0:\n",
    "        #            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        #                epoch, batch_idx * len(data), len(trainloader.dataset),\n",
    "        #                       100. * batch_idx / len(trainloader),\n",
    "        #                       loss.item() / len(data)))\n",
    "    if epoch % 200 == 0:\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "            epoch, train_loss / len(trainloader.dataset)))\n",
    "        train_losses.append(train_loss / len(trainloader.dataset))\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "\n",
    "###########################################################################\n",
    "mu_output = []\n",
    "logvar_output = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (data) in enumerate(trainloader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar, z = model(data)\n",
    "\n",
    "        mu_tensor = mu\n",
    "        mu_output.append(mu_tensor)\n",
    "        mu_result = torch.cat(mu_output, dim=0)\n",
    "\n",
    "        logvar_tensor = logvar\n",
    "        logvar_output.append(logvar_tensor)\n",
    "        logvar_result = torch.cat(logvar_output, dim=0)\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "pred = mu_result.cpu().detach().numpy()\n",
    "np.save('pred_vae32_1500_epochs.npy', pred)\n",
    "\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b49ec",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.402587Z"
    }
   },
   "outputs": [],
   "source": [
    "VAE_32 = np.load('pred_vae32_1500_epochs.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68182a0f",
   "metadata": {},
   "source": [
    "### Choose the best number of clusters (K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08fee60",
   "metadata": {},
   "source": [
    "This step take a lot of time because of the computation time of the silhouette coefficient (45min with google collab CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b443110a",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.403531Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_array = VAE_32\n",
    "km_scores = []\n",
    "vae32 = []\n",
    "db_score = []\n",
    "for i in range(5, 200, 5):\n",
    "    km = KMeans(n_clusters=i, random_state=25, n_init=10).fit(loaded_array)\n",
    "    km_preds = km.predict(loaded_array)\n",
    "    \n",
    "    #Calculating the silhouette coefficiant takes time\n",
    "    silhouette = silhouette_score(loaded_array, km_preds, random_state=25)\n",
    "    vae32.append(silhouette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b1b56",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.404556Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(250, 80))\n",
    "plt.title(\"\", fontsize=96)\n",
    "plt.scatter(x=[i for i in range(5, 200, 5)], y=vae32, s=6000, edgecolor='k', color='blue')\n",
    "plt.grid(True, linewidth=10)\n",
    "plt.xlabel(\"\\nNumber of clusters for the K-means Model\", fontsize=180)\n",
    "plt.ylabel(\"Silhouette score\\n\", fontsize=180)\n",
    "plt.xticks([i for i in range(5, 200, 5)], fontsize=150)\n",
    "plt.yticks(fontsize=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e2e553",
   "metadata": {},
   "source": [
    "### BIRCH train & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad0aa7e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.405396Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_array = cleaned\n",
    "\n",
    "brc = Birch(threshold=0.5, branching_factor=50, n_clusters=30, compute_labels=True, copy=True)\n",
    "brc.fit(loaded_array)\n",
    "birch_labels = brc.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574d7605",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.406290Z"
    }
   },
   "outputs": [],
   "source": [
    "ch = metrics.calinski_harabasz_score(loaded_array, birch_labels)\n",
    "print('ch Score: %.3f' % ch)\n",
    "\n",
    "ss = silhouette_score(loaded_array, birch_labels, metric='euclidean')\n",
    "print('Silhouetter Score: %.3f' % ss)\n",
    "\n",
    "DB = davies_bouldin_score(loaded_array, birch_labels)\n",
    "print('DB Score: %.3f' % DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d075be30",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.407213Z"
    }
   },
   "outputs": [],
   "source": [
    "VAE_16 = np.load('pred_vae16_1000_epochs.npy')\n",
    "VAE_32 = np.load('pred_vae32_1000_epochs.npy')\n",
    "VAE_64 = np.load('pred_vae64_1000_epochs.npy')\n",
    "AE_32 = np.load('pred_ae32_1000_epochs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(VAE_32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.408028Z"
    }
   },
   "id": "9215ed91d86625ca",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c0c89fd9",
   "metadata": {},
   "source": [
    "### Kmeans Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc86b1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.408917Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_array = VAE_32\n",
    "\n",
    "##K-Means & Internal clustering evaluations\n",
    "kmeans = KMeans(50,random_state=21, n_init=20)\n",
    "kmeans.fit(loaded_array)\n",
    "kmeanslabels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032dbe7c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.409699Z"
    }
   },
   "outputs": [],
   "source": [
    "ch = metrics.calinski_harabasz_score(loaded_array, kmeanslabels)\n",
    "print('ch Score: %.3f' % ch)\n",
    "\n",
    "ss = silhouette_score(loaded_array, kmeanslabels, metric='euclidean')\n",
    "print('Silhouetter Score: %.3f' % ss)\n",
    "\n",
    "DB = davies_bouldin_score(loaded_array, kmeanslabels)\n",
    "print('DB Score: %.3f' % DB)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "kmeanslabels_df = pd.DataFrame(kmeanslabels)\n",
    "kmeanslabels_df.to_csv('labels_VAE_32_Kmeans_K50.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.410526Z"
    }
   },
   "id": "d0fa4d0e88da5b1c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3ff93502",
   "metadata": {},
   "source": [
    "### Bisecting Kmeans train & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0bb34",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.411371Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_array = VAE_32\n",
    "\n",
    "for i in range(5,100,5):\n",
    "    print(i)\n",
    "    bisectingkmeans = BisectingKMeans(i,random_state=21, n_init=10)\n",
    "    bisectingkmeans.fit(loaded_array)\n",
    "    labels_bisectingkmeans = bisectingkmeans.labels_\n",
    "\n",
    "    ch = metrics.calinski_harabasz_score(loaded_array, labels_bisectingkmeans)\n",
    "    print('ch Score: %.3f' % ch)\n",
    "\n",
    "    ss = silhouette_score(loaded_array, labels_bisectingkmeans, metric='euclidean')\n",
    "    print('Silhouetter Score: %.3f' % ss)\n",
    "\n",
    "    DB = davies_bouldin_score(loaded_array, labels_bisectingkmeans)\n",
    "    print('DB Score: %.3f' % DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a1a8a",
   "metadata": {},
   "source": [
    "### DBSCAN train & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5deeb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.412248Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_array = VAE_32\n",
    "\n",
    "EPS = 2\n",
    "\n",
    "Dbscan = DBSCAN(eps = EPS)\n",
    "Dbscan.fit(loaded_array)\n",
    "labels_DBSCAN = Dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9158be7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.413030Z"
    }
   },
   "outputs": [],
   "source": [
    "# taking an input list\n",
    "input_list = labels_DBSCAN\n",
    "\n",
    "l1 = []\n",
    "\n",
    "# taking a counter\n",
    "count = 0\n",
    "\n",
    "for item in input_list:\n",
    "    if item not in l1:\n",
    "        count += 1\n",
    "        l1.append(item)\n",
    "\n",
    "# printing the output\n",
    "print(\"No of unique items are:\", count)\n",
    "print(\"values:\", l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a45cd4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.413879Z"
    }
   },
   "outputs": [],
   "source": [
    "ch = metrics.calinski_harabasz_score(loaded_array, labels_DBSCAN)\n",
    "print('ch Score: %.3f' % ch)\n",
    "\n",
    "ss = silhouette_score(loaded_array, labels_DBSCAN, metric='euclidean')\n",
    "print('Silhouetter Score: %.3f' % ss)\n",
    "\n",
    "DB = davies_bouldin_score(loaded_array, labels_DBSCAN)\n",
    "print('DB Score: %.3f' % DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### HDBSCAN train & evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3a01399e16a963d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loaded_array = VAE_32\n",
    "\n",
    "HDbscan = HDBSCAN(min_cluster_size=100)\n",
    "HDbscan.fit(loaded_array)\n",
    "labels_HDBSCAN = HDbscan.labels_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.414774Z"
    }
   },
   "id": "6862067d94da6701",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# taking an input list\n",
    "input_list = labels_HDBSCAN\n",
    "\n",
    "l1 = []\n",
    "\n",
    "# taking a counter\n",
    "count = 0\n",
    "\n",
    "for item in input_list:\n",
    "    if item not in l1:\n",
    "        count += 1\n",
    "        l1.append(item)\n",
    "\n",
    "# printing the output\n",
    "print(\"No of unique items are:\", count)\n",
    "print(\"values:\", l1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.415610Z"
    }
   },
   "id": "8bedc1ee10b93c18",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ch = metrics.calinski_harabasz_score(loaded_array, labels_HDBSCAN)\n",
    "print('ch Score: %.3f' % ch)\n",
    "\n",
    "ss = silhouette_score(loaded_array, labels_HDBSCAN, metric='euclidean')\n",
    "print('Silhouetter Score: %.3f' % ss)\n",
    "\n",
    "DB = davies_bouldin_score(loaded_array, labels_HDBSCAN)\n",
    "print('DB Score: %.3f' % DB)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.416388Z"
    }
   },
   "id": "c3b2aa934067bcc2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c93ae7de",
   "metadata": {},
   "source": [
    "### OPTICS train & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac38224",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.417132Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_array = VAE_32\n",
    "\n",
    "Optics = OPTICS(min_samples = 50)\n",
    "Optics.fit(loaded_array)\n",
    "labels_OPTICS = Optics.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8192fef",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.417883Z"
    }
   },
   "outputs": [],
   "source": [
    "# taking an input list\n",
    "input_list = labels_OPTICS\n",
    "\n",
    "l1 = []\n",
    "\n",
    "# taking a counter\n",
    "count = 0\n",
    "\n",
    "for item in input_list:\n",
    "    if item not in l1:\n",
    "        count += 1\n",
    "        l1.append(item)\n",
    "\n",
    "# printing the output\n",
    "print(\"No of unique items are:\", count)\n",
    "print(\"values:\", l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bced813",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.418713Z"
    }
   },
   "outputs": [],
   "source": [
    "ch = metrics.calinski_harabasz_score(loaded_array, labels_OPTICS)\n",
    "print('ch Score: %.3f' % ch)\n",
    "\n",
    "ss = silhouette_score(loaded_array, labels_OPTICS, metric='euclidean')\n",
    "print('Silhouetter Score: %.3f' % ss)\n",
    "\n",
    "DB = davies_bouldin_score(loaded_array, labels_OPTICS)\n",
    "print('DB Score: %.3f' % DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49653922",
   "metadata": {},
   "source": [
    "### Meanshift train & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369d9b2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.419210Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_array = VAE_32\n",
    "\n",
    "\n",
    "meanshift = MeanShift(bandwidth = 3)\n",
    "meanshift.fit(loaded_array)\n",
    "labels_meanshift = meanshift.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02af913b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.419742Z"
    }
   },
   "outputs": [],
   "source": [
    "# taking an input list\n",
    "input_list = labels_meanshift\n",
    "\n",
    "l1 = []\n",
    "\n",
    "# taking a counter\n",
    "count = 0\n",
    "\n",
    "for item in input_list:\n",
    "    if item not in l1:\n",
    "        count += 1\n",
    "        l1.append(item)\n",
    "\n",
    "# printing the output\n",
    "print(\"No of unique items are:\", count)\n",
    "print(\"values:\", l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43b53c5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.420269Z"
    }
   },
   "outputs": [],
   "source": [
    "ch = metrics.calinski_harabasz_score(loaded_array, labels_meanshift)\n",
    "print('ch Score: %.3f' % ch)\n",
    "\n",
    "ss = silhouette_score(loaded_array, labels_meanshift, metric='euclidean')\n",
    "print('Silhouetter Score: %.3f' % ss)\n",
    "\n",
    "DB = davies_bouldin_score(loaded_array, labels_meanshift)\n",
    "print('DB Score: %.3f' % DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fb0245",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.420811Z"
    }
   },
   "outputs": [],
   "source": [
    "meanshift.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf5b723",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e016b8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.421327Z"
    }
   },
   "outputs": [],
   "source": [
    "## Visualize Results\n",
    "labels_df = pd.read_csv('labels_VAE_32_Kmeans_K50.csv')\n",
    "labels = labels_df.to_numpy()\n",
    "\n",
    "# 1. Density Plot\n",
    "pred = pd.DataFrame(data=VAE_32)\n",
    "\n",
    "\n",
    "molecules = pd.read_csv(\"compound-annotation.csv\", sep=\",\")\n",
    "molecules = molecules[molecules[\"SMILES\"].notna()]\n",
    "molecules = molecules.drop_duplicates(subset=['SMILES'], ignore_index=True)\n",
    "smiles = molecules[[\"SMILES\"]]\n",
    "\n",
    "pred.insert(0, 'SMILES', smiles)\n",
    "\n",
    "pred.insert(1, \"clusters\", labels)\n",
    "\n",
    "s = []\n",
    "i = 0\n",
    "index = []\n",
    "K = 50 #number of clusters\n",
    "for j in range(0, K):\n",
    "    s = pred.loc[pred['clusters'] == j, 'SMILES']\n",
    "    s = s.to_list()\n",
    "    for s2 in s:\n",
    "        i = i + 1\n",
    "    index.append(i)\n",
    "    i = 0\n",
    "\n",
    "###################################\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "x = []\n",
    "for i in range(1, K+1):\n",
    "    x.append(i)\n",
    "\n",
    "font = {'size': 22}\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "langs = x\n",
    "students = index\n",
    "ax.bar(langs, students)\n",
    "ax.set_ylabel('Number of molecules in each cluster\\n', fontsize=34)\n",
    "ax.set_xlabel('\\nNumber of clusters ', fontsize=34)\n",
    "ax.set_xticks([k for k in range(0, K+1, 10)])\n",
    "#ax.set_xticks( fontsize = 20)\n",
    "ax.set_title('', fontsize=14)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224f360a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.421870Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. t-SNE plot\n",
    "loaded_array = VAE_pred\n",
    "labels = labels_VAE_Kmeans\n",
    "\n",
    "tsne_comp = TSNE(n_components=2, perplexity=30, random_state=30, n_iter=1000).fit_transform(loaded_array)\n",
    "\n",
    "tsne_df = pd.DataFrame(data=tsne_comp, columns=['t-SNE1', 't-SNE2'])\n",
    "tsne_df.head()\n",
    "\n",
    "tsne_df = pd.concat([tsne_df, pd.DataFrame({'cluster': labels})], axis=1)\n",
    "tsne_df['cluster'] += 1\n",
    "tsne_df.head()\n",
    "\n",
    "text = []\n",
    "for i in range(1, 31):\n",
    "    text.append(str(i))\n",
    "len(text)\n",
    "\n",
    "plt.figure(figsize=(25, 20))\n",
    "sns.set(font_scale=3)\n",
    "z = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "ax = sns.scatterplot(x=\"t-SNE1\", y=\"t-SNE2\", hue=\"cluster\", data=tsne_df, palette=z)\n",
    "# ax = sns.color_palette(\"mako\", as_cmap=True)\n",
    "x = tsne_df['t-SNE1']\n",
    "y = tsne_df['t-SNE2']\n",
    "for i in range(0, 30):\n",
    "    plt.annotate(text[i], (x[i], y[i] + .2), size=22, color='black', weight='bold')\n",
    "# plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0, ncol = 3 )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0b0da5",
   "metadata": {},
   "source": [
    "### Resume of the results obtained for each methods used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09da1a2",
   "metadata": {},
   "source": [
    "Be careful the score for the method using the VAE are computed in the latent space and not in the 'entire' departures space. So, we can not compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1103399",
   "metadata": {},
   "source": [
    "###### Kmeans in the entire Space"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The metrics have been computed in the input space"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e154eaf4cacd6b1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "| dimension of the space of features used in the model | Method of clustering | Number of clusters | eps | thresold | branching factor | CH       | SC    | DB    |\n",
    "|------------------------------------------------------|----------------------|--------------------|-----|----------|------------------|----------|-------|-------|\n",
    "| 251: 'basic' space                                   | Kmeans               | 130                | -   | -        | -                | 533.264  | 0.076 | 1.949 |\n",
    "| 251: 'basic' space                                   | Kmeans               | 30                 | -   | -        | -                | 1011.817 | 0.058 | 2.329 |"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23ff839f505d09c6"
  },
  {
   "cell_type": "markdown",
   "id": "732fb5aa",
   "metadata": {},
   "source": [
    "###### Kmeans in the latent Space"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The metrics have been computed in the latent space\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c64ef04eb4b17bfa"
  },
  {
   "cell_type": "markdown",
   "id": "0fbeb070",
   "metadata": {},
   "source": [
    "| dimension of the space of features used in the model | Method of clustering | Number of clusters | CH           | SC        | DB        |\n",
    "|------------------------------------------------------|----------------------|--------------------|--------------|-----------|-----------|\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 25                 | **6747.221** | 0.239     | 1.100     |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 26                 | 6688.481     | 0.236     | 1.103     |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 27                 | 6616.331     | 0.236     | 1.125     |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 28                 | 6579.824     | 0.239     | 1.105     |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 29                 | 6503.428     | 0.239     | **1.085** |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 30                 | 6452.638     | **0.240** | 1.091     |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 31                 | 6353.183     | 0.234     | 1.130     |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 35                 | 6100.477     | 0.231     | 1.139     |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 40                 | 5901.286     | 0.231     | 1.169     |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 50                 | 5454.641     | 0.232     | 1.153     |\n",
    "| 'latent' space (VAE_32)                              | Kmeans               | 80                 | 4620.676     | 0.234     | 1.147     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abea9d7",
   "metadata": {},
   "source": [
    "###### BIRCH in the latent Space"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The metrics have been computed in the latent space\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64fbf46ea4752da9"
  },
  {
   "cell_type": "markdown",
   "id": "d3b70b01",
   "metadata": {},
   "source": [
    "| dimension of the space of features used in the model | Method of clustering | Number of clusters | eps | thresold | branching factor | CH           | SC        | DB        |\n",
    "|------------------------------------------------------|----------------------|--------------------|-----|----------|------------------|--------------|-----------|-----------|\n",
    "| 32: 'latent' space (VAE_32)                          | Birch                | 10                 | -   | 0.5      | 50               | 3966.486     | 0.133     | 1.386     |\n",
    "| 32: 'latent' space (VAE_32)                          | Birch                | 15                 | -   | 0.5      | 50               | **4262.498** | 0.129     | 1.334     |\n",
    "| 32: 'latent' space (VAE_32)                          | Birch                | 20                 | -   | 0.5      | 50               | 3832.337     | 0.145     | **1.248** |\n",
    "| 32: 'latent' space (VAE_32)                          | Birch                | 25                 | -   | 0.5      | 50               | 3809.872     | **0.165** | 1.140     |\n",
    "| 32: 'latent' space (VAE_32)                          | Birch                | 30                 | -   | 0.5      | 50               | 3451.681     | 0.151     | 1.140     |\n",
    "| 32: 'latent' space (VAE_32)                          | Birch                | 35                 | -   | 0.5      | 50               | 3589.347     | 0.149     | 1.159     |\n",
    "| 32: 'latent' space (VAE_32)                          | Birch                | 40                 | -   | 0.5      | 50               | 3260.281     | 0.147     | 1.146     |\n",
    "| 32: 'latent' space (VAE_32)                          | Birch                | 45                 | -   | 0.5      | 50               | 3232.431     | 0.154     | 1.168     |\n",
    "| 32: 'latent' space (VAE_32)                          | Birch                | 50                 | -   | 0.5      | 50               | 3080.691     | 0.149     | 1.177     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d707b1",
   "metadata": {},
   "source": [
    "###### DBSCAN in the latent Space"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The metrics have been computed in the latent space"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb12862c60dec64d"
  },
  {
   "cell_type": "markdown",
   "id": "38d76c61",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| dimension of the space of features used in the model | Method of clustering | Number of clusters  | eps | CH      | SC     | DB    |\n",
    "|------------------------------------------------------|----------------------|---------------------|-----|---------|--------|-------|\n",
    "| 32: 'latent' space (VAE)                             | DBSCAN               | 94 + outlier points | 0.3 | 170.611 | -0.344 | 1.602 |\n",
    "| 32: 'latent' space (VAE)                             | DBSCAN               | 19 + outlier points | 0.5 | 100.915 | -0.115 | 1.802 |\n",
    "| 32: 'latent' space (VAE)                             | DBSCAN               | 15 + outlier points | 0.6 | 112.517 | 0.094  | 1.631 |\n",
    "| 32: 'latent' space (VAE)                             | DBSCAN               | 12 + outlier points | 0.7 | 137.627 | 0.232  | 1.556 |\n",
    "| 32: 'latent' space (VAE)                             | DBSCAN               | 6 + outlier points  | 0.8 | 198.313 | 0.348  | 1.603 |\n",
    "| 32: 'latent' space (VAE)                             | DBSCAN               | 9 + outlier points  | 1.2 | 148.970 | 0.443  | 1.608 |\n",
    "| 32: 'latent' space (VAE)                             | DBSCAN               | 4 + outlier points  | 1.5 | 128.754 | 0.486  | 1.241 |\n",
    "| 32: 'latent' space (VAE)                             | DBSCAN               | 2 + outlier points  | 2   | 132.724 | 0.575  | 0.968 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9662b30",
   "metadata": {},
   "source": [
    "###### OPTICS in the latent Space"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The metrics have been computed in the latent space\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eeaf06f17c5096d2"
  },
  {
   "cell_type": "markdown",
   "id": "e019bb1b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| dimension of the space of features used in the model | Method of clustering | Number of clusters    | min_samples | max_eps                | CH      | SC     | DB    |\n",
    "|------------------------------------------------------|----------------------|-----------------------|-------------|------------------------|---------|--------|-------|\n",
    "| 32: 'latent' space (VAE)                             | OPTICS               | 1493 + outlier points | 5           | np.inf (default value) | 11.185  | -0.532 | 1.236 |\n",
    "| 32: 'latent' space (VAE)                             | OPTICS               | 280 + outlier points  | 10          | np.inf (default value) | 25.169  | -0.636 | 1.116 |\n",
    "| 32: 'latent' space (VAE)                             | OPTICS               | 107 + outlier points  | 15          | np.inf (default value) | 47.644  | -0.598 | 1.012 |\n",
    "| 32: 'latent' space (VAE)                             | OPTICS               | 23 + outlier points   | 25          | np.inf (default value) | 113.761 | -0.355 | 0.928 |\n",
    "| 32: 'latent' space (VAE)                             | OPTICS               | 5 + outlier points    | 50          | np.inf (default value) | 121.111 | -0.150 | 0.936 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57735e1c",
   "metadata": {},
   "source": [
    "###### Bisecting Kmeans in the latent Space"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The metrics have been computed in the latent space\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9bc7ada0afcde77"
  },
  {
   "cell_type": "markdown",
   "id": "225f64de",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| dimension of the space of features used in the model | Method of clustering | Number of clusters | CH       | SC        | DB    |\n",
    "|------------------------------------------------------|----------------------|--------------------|----------|-----------|-------|\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 5                  | 8112.950 | 0.161     | 1.621 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 10                 | 6677.805 | 0.140     | 1.561 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 15                 | 6371.956 | **0.163** | 1.469 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 20                 | 5715.197 | 0.156     | 1.424 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 25                 | 5190.460 | 0.144     | 1.437 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 30                 | 4971.206 | 0.153     | 1.390 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 35                 | 4753.198 | 0.152     | 1.455 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 40                 | 4671.040 | 0.157     | 1.410 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 45                 | 4443.872 | 0.154     | 1.419 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 50                 | 4242.036 | 0.153     | 1.431 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 60                 | 3952.478 | 0.150     | 1.408 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 70                 | 3695.272 | 0.146     | 1.410 |\n",
    "| 32: 'latent' space (VAE)                             | Bisecting Kmeans     | 80                 | 3516.554 | 0.144     | 1.399 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9e683b",
   "metadata": {},
   "source": [
    "###### Bisecting Kmeans in the latent Space"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The metrics have been computed in the latent space"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb97a847a1fcd9b2"
  },
  {
   "cell_type": "markdown",
   "id": "daa5a0a8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| dimension of the space of features used in the model | Method of clustering | Number of clusters | bandwith | CH      | SC    | DB    |\n",
    "|------------------------------------------------------|----------------------|--------------------|----------|---------|-------|-------|\n",
    "| 32: 'latent' space (VAE)                             | Meanshift            | 22                 | None     | 151.947 | 0.233 | 0.847 |\n",
    "| 32: 'latent' space (VAE)                             | Meanshift            | 8                  | 3        | 213.409 | 0.484 | 1.329 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc82e0e",
   "metadata": {},
   "source": [
    "### Comparaison to the original article"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The metrics have been computed in the input space"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "555cce672aca9dd2"
  },
  {
   "cell_type": "markdown",
   "id": "8ee777b0",
   "metadata": {},
   "source": [
    "| dimension of the space of features used in the model | Clustering method | Number of clusters | CH           | SC        | DB        |\n",
    "|------------------------------------------------------|-------------------|--------------------|--------------|-----------|-----------|\n",
    "| 251: 'input' space                                   | Kmeans            | 30                 | 1011.817     | 0.058     | 2.329     |\n",
    "| 251: 'input' space                                   | BIRCH             | 30                 | 840.342      | 0.042     | 2.181     |\n",
    "| 251: 'input' space                                   | VAE(16) + Kmeans  | 50                 | 4070.465     | 0.204     | 1.253     |\n",
    "| 251: 'input' space                                   | VAE(32) + Kmeans  | 50                 | **5472.521** | **0.230** | **1.172** | \n",
    "| 251: 'input' space                                   | VAE(64) + Kmeans  | 70                 | 2116.804     | 0.156     | 1.425     |\n",
    "| 251: 'input' space                                   | Kmeans            | 50                 | 805.715      | 0.064     | 2.060     |"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-26T12:52:32.422377Z"
    }
   },
   "id": "51f280724df81cda"
  },
  {
   "cell_type": "markdown",
   "source": [
    "| dimension of the space of features used in the model | Method of clustering        | Number of clusters  | CH           | SC        | DB        |\n",
    "|------------------------------------------------------|-----------------------------|---------------------|--------------|-----------|-----------|\n",
    "| 32: 'latent' space (VAE)                             | VAE (32) + DBSCAN           | 19 + outlier points | 100.915      | -0.115    | 1.802     |\n",
    "| 32: 'latent' space (VAE)                             | VAE (32) + DBSCAN           | 12 + outlier points | 137.627      | 0.232     | 1.556     |\n",
    "| 32: 'latent' space (VAE)                             | VAE (32) + Meanshift        | 22                  | 151.947      | 0.233     | **0.847** |\n",
    "| 32: 'latent' space (VAE)                             | VAE (32) + Meanshift        | 8                   | 213.409      | **0.484** | 1.329     |\n",
    "| 32: 'latent' space (VAE)                             | VAE (32) + HDBSCAN          | 11 + outlier points | 652.650      | -0.123    | 2.234     |\n",
    "| 32: 'latent' space (VAE)                             | VAE (32) + Birch            | 15                  | 4262.498     | 0.129     | 1.334     |\n",
    "| 32: 'latent' space (VAE)                             | VAE (32) + Kmeans           | 15                  | **7575.908** | 0.223     | 1.199     |\n",
    "| 32: 'latent' space (VAE)                             | VAE (32) + Bisecting Kmeans | 15                  | 6371.956     | 0.163     | 1.469     |"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bb81b00a5e057b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GAN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "974241af0067fff3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1         2         3         4         5         6  \\\n0    -0.338905 -0.023917  0.467405 -0.444836 -0.698588 -0.102157 -0.078013   \n1     1.994625 -0.205199  0.500019 -1.300564  0.961503 -0.233546 -0.331582   \n2    -0.415160  0.040135  0.239332 -0.602974  0.457500 -0.066492 -0.499016   \n3     2.976938  0.956001  0.140284 -0.953755  0.352027  0.036427 -0.127167   \n4    -0.226614  0.895039 -0.040288  0.041846 -0.502408 -0.020622  0.195022   \n...        ...       ...       ...       ...       ...       ...       ...   \n2121 -0.366112  7.014571  2.003236 -0.227992 -0.266879  0.476123  0.516524   \n2122  0.205047  7.312754  1.930783 -0.284909 -0.108333  0.412790  0.600211   \n2123  1.389624  6.805990  1.080811 -0.425817  0.062374  0.620463  0.499063   \n2124 -2.127185  6.003349  2.584577  0.439142  0.215485  0.311160 -0.059253   \n2125 -1.530834  5.196856  2.574403  0.066535 -0.064434  0.546624  0.385741   \n\n             7         8         9  ...       241       242       243  \\\n0    -0.213770 -0.400386 -0.135146  ... -0.213633 -0.429789 -0.127043   \n1    -0.250344 -0.012700 -0.125824  ... -0.213633 -0.429789 -0.127043   \n2    -0.067857 -0.220223 -0.102129  ... -0.213633 -0.429789 -0.127043   \n3    -0.016281 -0.169218  0.002586  ... -0.213633 -0.429789 -0.127043   \n4    -0.236531 -0.068346 -0.126428  ... -0.213633 -0.429789 -0.127043   \n...        ...       ...       ...  ...       ...       ...       ...   \n2121 -0.352058 -0.295642 -0.320242  ... -0.213633 -0.429789 -0.127043   \n2122 -0.328908 -0.280607 -0.264797  ... -0.213633 -0.429789 -0.127043   \n2123 -0.199597 -0.193428 -0.141554  ... -0.213633 -0.429789 -0.127043   \n2124  0.257399 -0.392334 -0.063871  ... -0.213633 -0.429789 -0.127043   \n2125 -0.240769 -0.255194 -0.294925  ... -0.213633 -0.429789 -0.127043   \n\n           244       245       246       247       248       249       250  \n0    -0.025679 -0.090911 -0.225666 -0.007971 -0.288089 -0.183115 -0.308708  \n1    -0.025679 -0.090911 -0.225666 -0.007971  3.240492 -0.183115 -0.308708  \n2    -0.025679 -0.090911 -0.225666 -0.007971 -0.288089 -0.183115 -0.308708  \n3    -0.025679 -0.090911 -0.225666 -0.007971  3.240492 -0.183115 -0.308708  \n4    -0.025679 -0.090911 -0.225666 -0.007971 -0.288089 -0.183115 -0.308708  \n...        ...       ...       ...       ...       ...       ...       ...  \n2121 -0.025679 -0.090911 -0.225666 -0.007971 -0.288089 -0.183115 -0.308708  \n2122 -0.025679 -0.090911 -0.225666 -0.007971 -0.288089 -0.183115 -0.308708  \n2123 -0.025679 -0.090911  8.762322 -0.007971 -0.288089 -0.183115 -0.308708  \n2124 -0.025679 -0.090911 -0.225666 -0.007971 -0.288089 -0.183115 -0.308708  \n2125 -0.025679 -0.090911  8.762322 -0.007971 -0.288089 -0.183115 -0.308708  \n\n[2126 rows x 251 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>241</th>\n      <th>242</th>\n      <th>243</th>\n      <th>244</th>\n      <th>245</th>\n      <th>246</th>\n      <th>247</th>\n      <th>248</th>\n      <th>249</th>\n      <th>250</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.338905</td>\n      <td>-0.023917</td>\n      <td>0.467405</td>\n      <td>-0.444836</td>\n      <td>-0.698588</td>\n      <td>-0.102157</td>\n      <td>-0.078013</td>\n      <td>-0.213770</td>\n      <td>-0.400386</td>\n      <td>-0.135146</td>\n      <td>...</td>\n      <td>-0.213633</td>\n      <td>-0.429789</td>\n      <td>-0.127043</td>\n      <td>-0.025679</td>\n      <td>-0.090911</td>\n      <td>-0.225666</td>\n      <td>-0.007971</td>\n      <td>-0.288089</td>\n      <td>-0.183115</td>\n      <td>-0.308708</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.994625</td>\n      <td>-0.205199</td>\n      <td>0.500019</td>\n      <td>-1.300564</td>\n      <td>0.961503</td>\n      <td>-0.233546</td>\n      <td>-0.331582</td>\n      <td>-0.250344</td>\n      <td>-0.012700</td>\n      <td>-0.125824</td>\n      <td>...</td>\n      <td>-0.213633</td>\n      <td>-0.429789</td>\n      <td>-0.127043</td>\n      <td>-0.025679</td>\n      <td>-0.090911</td>\n      <td>-0.225666</td>\n      <td>-0.007971</td>\n      <td>3.240492</td>\n      <td>-0.183115</td>\n      <td>-0.308708</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.415160</td>\n      <td>0.040135</td>\n      <td>0.239332</td>\n      <td>-0.602974</td>\n      <td>0.457500</td>\n      <td>-0.066492</td>\n      <td>-0.499016</td>\n      <td>-0.067857</td>\n      <td>-0.220223</td>\n      <td>-0.102129</td>\n      <td>...</td>\n      <td>-0.213633</td>\n      <td>-0.429789</td>\n      <td>-0.127043</td>\n      <td>-0.025679</td>\n      <td>-0.090911</td>\n      <td>-0.225666</td>\n      <td>-0.007971</td>\n      <td>-0.288089</td>\n      <td>-0.183115</td>\n      <td>-0.308708</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.976938</td>\n      <td>0.956001</td>\n      <td>0.140284</td>\n      <td>-0.953755</td>\n      <td>0.352027</td>\n      <td>0.036427</td>\n      <td>-0.127167</td>\n      <td>-0.016281</td>\n      <td>-0.169218</td>\n      <td>0.002586</td>\n      <td>...</td>\n      <td>-0.213633</td>\n      <td>-0.429789</td>\n      <td>-0.127043</td>\n      <td>-0.025679</td>\n      <td>-0.090911</td>\n      <td>-0.225666</td>\n      <td>-0.007971</td>\n      <td>3.240492</td>\n      <td>-0.183115</td>\n      <td>-0.308708</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.226614</td>\n      <td>0.895039</td>\n      <td>-0.040288</td>\n      <td>0.041846</td>\n      <td>-0.502408</td>\n      <td>-0.020622</td>\n      <td>0.195022</td>\n      <td>-0.236531</td>\n      <td>-0.068346</td>\n      <td>-0.126428</td>\n      <td>...</td>\n      <td>-0.213633</td>\n      <td>-0.429789</td>\n      <td>-0.127043</td>\n      <td>-0.025679</td>\n      <td>-0.090911</td>\n      <td>-0.225666</td>\n      <td>-0.007971</td>\n      <td>-0.288089</td>\n      <td>-0.183115</td>\n      <td>-0.308708</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2121</th>\n      <td>-0.366112</td>\n      <td>7.014571</td>\n      <td>2.003236</td>\n      <td>-0.227992</td>\n      <td>-0.266879</td>\n      <td>0.476123</td>\n      <td>0.516524</td>\n      <td>-0.352058</td>\n      <td>-0.295642</td>\n      <td>-0.320242</td>\n      <td>...</td>\n      <td>-0.213633</td>\n      <td>-0.429789</td>\n      <td>-0.127043</td>\n      <td>-0.025679</td>\n      <td>-0.090911</td>\n      <td>-0.225666</td>\n      <td>-0.007971</td>\n      <td>-0.288089</td>\n      <td>-0.183115</td>\n      <td>-0.308708</td>\n    </tr>\n    <tr>\n      <th>2122</th>\n      <td>0.205047</td>\n      <td>7.312754</td>\n      <td>1.930783</td>\n      <td>-0.284909</td>\n      <td>-0.108333</td>\n      <td>0.412790</td>\n      <td>0.600211</td>\n      <td>-0.328908</td>\n      <td>-0.280607</td>\n      <td>-0.264797</td>\n      <td>...</td>\n      <td>-0.213633</td>\n      <td>-0.429789</td>\n      <td>-0.127043</td>\n      <td>-0.025679</td>\n      <td>-0.090911</td>\n      <td>-0.225666</td>\n      <td>-0.007971</td>\n      <td>-0.288089</td>\n      <td>-0.183115</td>\n      <td>-0.308708</td>\n    </tr>\n    <tr>\n      <th>2123</th>\n      <td>1.389624</td>\n      <td>6.805990</td>\n      <td>1.080811</td>\n      <td>-0.425817</td>\n      <td>0.062374</td>\n      <td>0.620463</td>\n      <td>0.499063</td>\n      <td>-0.199597</td>\n      <td>-0.193428</td>\n      <td>-0.141554</td>\n      <td>...</td>\n      <td>-0.213633</td>\n      <td>-0.429789</td>\n      <td>-0.127043</td>\n      <td>-0.025679</td>\n      <td>-0.090911</td>\n      <td>8.762322</td>\n      <td>-0.007971</td>\n      <td>-0.288089</td>\n      <td>-0.183115</td>\n      <td>-0.308708</td>\n    </tr>\n    <tr>\n      <th>2124</th>\n      <td>-2.127185</td>\n      <td>6.003349</td>\n      <td>2.584577</td>\n      <td>0.439142</td>\n      <td>0.215485</td>\n      <td>0.311160</td>\n      <td>-0.059253</td>\n      <td>0.257399</td>\n      <td>-0.392334</td>\n      <td>-0.063871</td>\n      <td>...</td>\n      <td>-0.213633</td>\n      <td>-0.429789</td>\n      <td>-0.127043</td>\n      <td>-0.025679</td>\n      <td>-0.090911</td>\n      <td>-0.225666</td>\n      <td>-0.007971</td>\n      <td>-0.288089</td>\n      <td>-0.183115</td>\n      <td>-0.308708</td>\n    </tr>\n    <tr>\n      <th>2125</th>\n      <td>-1.530834</td>\n      <td>5.196856</td>\n      <td>2.574403</td>\n      <td>0.066535</td>\n      <td>-0.064434</td>\n      <td>0.546624</td>\n      <td>0.385741</td>\n      <td>-0.240769</td>\n      <td>-0.255194</td>\n      <td>-0.294925</td>\n      <td>...</td>\n      <td>-0.213633</td>\n      <td>-0.429789</td>\n      <td>-0.127043</td>\n      <td>-0.025679</td>\n      <td>-0.090911</td>\n      <td>8.762322</td>\n      <td>-0.007971</td>\n      <td>-0.288089</td>\n      <td>-0.183115</td>\n      <td>-0.308708</td>\n    </tr>\n  </tbody>\n</table>\n<p>2126 rows  251 columns</p>\n</div>"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molecules = pd.read_csv(\"compound-annotation.csv\", sep=\",\")\n",
    "molecules = molecules[molecules[\"SMILES\"].notna()]\n",
    "molecules = molecules.drop_duplicates(subset=['SMILES'], ignore_index=True)\n",
    "smiles = molecules[[\"SMILES\"]]\n",
    "\n",
    "labels_df = pd.read_csv('labels_VAE_32_Kmeans_K50.csv')\n",
    "labels_df.columns = ['Labels']\n",
    "\n",
    "cluster = smiles.join(labels_df)\n",
    "\n",
    "VAE_32 = np.load('pred_vae32_1000_epochs.npy')\n",
    "VAE_32_df = pd.DataFrame(data=VAE_32)\n",
    "cluster_VAE = cluster.join(VAE_32_df)\n",
    "cluster_VAE = cluster_VAE[cluster_VAE['Labels']==23]\n",
    "cluster_VAE = cluster_VAE.reset_index()\n",
    "cluster_VAE = cluster_VAE.drop([\"Labels\", \"index\", \"SMILES\"], axis=1)\n",
    "cluster_VAE\n",
    "\n",
    "\n",
    "cleaned = pd.read_csv('cleaned.csv')\n",
    "cluster_cleaned = cluster.join(cleaned)\n",
    "cluster_cleaned = cluster_cleaned[cluster_cleaned['Labels']==23]\n",
    "cluster_cleaned = cluster_cleaned.reset_index()\n",
    "cluster_cleaned = cluster_cleaned.drop([\"Labels\", \"index\", \"SMILES\"], axis=1)\n",
    "cluster_cleaned"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:52:55.674027Z",
     "start_time": "2024-01-26T12:52:54.249113Z"
    }
   },
   "id": "cf22fb5a71027974",
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  6847\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.use_deterministic_algorithms(True) # Needed for reproducible results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:52:55.677156Z",
     "start_time": "2024-01-26T12:52:55.674722Z"
    }
   },
   "id": "c935d8c8c9863fc3",
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 1\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 251\n",
    "# Size of feature maps in generator\n",
    "ngf = 32\n",
    "H = 128\n",
    "H2 = 64\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 32\n",
    "# Number of training epochs\n",
    "num_epochs = 5\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "# Beta1 hyperparameter for Adam optimizers\n",
    "beta1 = 0.5\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:52:55.679034Z",
     "start_time": "2024-01-26T12:52:55.677432Z"
    }
   },
   "id": "479ab77a89a94f3f",
   "execution_count": 109
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# We can use an image folder dataset the way we have it setup.\n",
    "# Create the dataset\n",
    "dataset = np.float32(cluster_cleaned)\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:53:25.900075Z",
     "start_time": "2024-01-26T12:53:25.882879Z"
    }
   },
   "id": "71c319bc84992436",
   "execution_count": 111
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# custom weights initialization called on ``netG`` and ``netD``\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:53:25.913772Z",
     "start_time": "2024-01-26T12:53:25.902001Z"
    }
   },
   "id": "18c49dc61859b927",
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Generator Code\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(nz, H),\n",
    "            nn.BatchNorm1d(H),\n",
    "            nn.ReLU(True),\n",
    "                \n",
    "            nn.Linear(H, H2),\n",
    "            nn.BatchNorm1d(H2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Linear(H2, H2),\n",
    "            nn.BatchNorm1d(H2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Linear(H2, ngf),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Linear(ngf, ngf),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:53:25.924552Z",
     "start_time": "2024-01-26T12:53:25.915142Z"
    }
   },
   "id": "868473c44461be96",
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=251, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the generator\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-GPU if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply the ``weights_init`` function to randomly initialize all weights\n",
    "#  to ``mean=0``, ``stdev=0.02``.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:53:25.942475Z",
     "start_time": "2024-01-26T12:53:25.925389Z"
    }
   },
   "id": "725ee472c9a1f6ed",
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(ndf, ndf),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(ndf, H2),\n",
    "            nn.BatchNorm2d(H2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(H2, H2),\n",
    "            nn.BatchNorm1d(H2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(H2, H),\n",
    "            nn.BatchNorm1d(H),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(H, nz),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T13:01:29.622857Z",
     "start_time": "2024-01-26T13:01:29.614739Z"
    }
   },
   "id": "bfcee391d510bf45",
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Linear(in_features=128, out_features=251, bias=True)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-GPU if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Apply the ``weights_init`` function to randomly initialize all weights\n",
    "# like this: ``to mean=0, stdev=0.2``.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T13:01:31.747924Z",
     "start_time": "2024-01-26T13:01:31.738787Z"
    }
   },
   "id": "3515557783bfcbb8",
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initialize the ``BCELoss`` function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T13:01:52.078866Z",
     "start_time": "2024-01-26T13:01:52.070404Z"
    }
   },
   "id": "3d5fc88fae8d3471",
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x251 and 32x32)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[122], line 25\u001B[0m\n\u001B[1;32m     23\u001B[0m label \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfull((b_size,), real_label, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# Forward pass real batch through D\u001B[39;00m\n\u001B[0;32m---> 25\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mnetD\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreal_cpu\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# Calculate loss on all-real batch\u001B[39;00m\n\u001B[1;32m     27\u001B[0m errD_real \u001B[38;5;241m=\u001B[39m criterion(output, label)\n",
      "File \u001B[0;32m~/Documents/A-Ecole/2A/Projet Recherche/molecules-clustering/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/A-Ecole/2A/Projet Recherche/molecules-clustering/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[119], line 26\u001B[0m, in \u001B[0;36mDiscriminator.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m---> 26\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/A-Ecole/2A/Projet Recherche/molecules-clustering/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/A-Ecole/2A/Projet Recherche/molecules-clustering/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/A-Ecole/2A/Projet Recherche/molecules-clustering/venv/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 215\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/Documents/A-Ecole/2A/Projet Recherche/molecules-clustering/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/A-Ecole/2A/Projet Recherche/molecules-clustering/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/A-Ecole/2A/Projet Recherche/molecules-clustering/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (1x251 and 32x32)"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T13:02:05.526418Z",
     "start_time": "2024-01-26T13:01:53.755257Z"
    }
   },
   "id": "f9a0fa1cc6c18785",
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-26T12:53:32.652763Z"
    }
   },
   "id": "b4da10bf5c412dc4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
